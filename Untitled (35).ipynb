{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9828606f-75c3-497f-9816-3072dc4c0095",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "344dbb82-821a-48a6-bd41-51d97dfa6b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA (Analysis of Variance) is a statistical technique used to compare the means of two or more groups. It makes several assumptions about the data to ensure the validity of the results. Here are the key assumptions required for conducting ANOVA:\n",
    "\n",
    "# 1. Independence: The observations within each group should be independent of each other. This means that the values in one group should not be influenced by or dependent on the values in another group.\n",
    "\n",
    "# 2. Normality: The data within each group should follow a normal distribution. This assumption is important because ANOVA relies on the normality assumption to calculate probabilities and make inferences.\n",
    "\n",
    "# 3. Homogeneity of variances: The variability of scores (variances) in each group should be approximately equal. Homogeneity of variances ensures that the groups have a similar spread of values, allowing for meaningful comparisons.\n",
    "\n",
    "# Violations of these assumptions can impact the validity of ANOVA results. Here are examples of violations that could impact the validity:\n",
    "\n",
    "# 1. Violation of independence: If the observations within the groups are not independent, it can lead to biased results. For example, if the same subjects are included in multiple groups or if there is a dependency between the observations due to clustering or repeated measures, the assumption of independence is violated.\n",
    "\n",
    "# 2. Violation of normality: If the data within the groups deviate significantly from a normal distribution, the ANOVA results may not be reliable. This is particularly important when the sample sizes are small. Violations can occur when there are extreme outliers, skewed distributions, or heavy tails in the data.\n",
    "\n",
    "# 3. Violation of homogeneity of variances: When the variances across the groups are not equal, the assumptions underlying ANOVA may not hold. This can result in inflated or deflated Type I error rates and can affect the power of the analysis. Violations can occur when there is heteroscedasticity, meaning that the spread of values differs across the groups.\n",
    "\n",
    "# When these assumptions are violated, alternative statistical tests or adjustments can be used. Non-parametric tests, such as the Kruskal-Wallis test, can be used when the normality assumption is violated. Robust versions of ANOVA, such as Welch's ANOVA, can be used when the assumption of homogeneity of variances is violated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a86b59ab-6619-4aec-95b5-7d2e89eaaffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39e76372-82a0-4373-a7c0-413bb2749f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The three types of ANOVA are:\n",
    "\n",
    "# 1. One-Way ANOVA: One-Way ANOVA is used when there is a single categorical independent variable (also known as a factor) and a continuous dependent variable. It is used to determine if there are any statistically significant differences between the means of three or more groups. For example, a One-Way ANOVA can be used to compare the average test scores of students from different schools (where the schools are the groups) to see if there are any significant differences in performance.\n",
    "\n",
    "# 2. Two-Way ANOVA: Two-Way ANOVA is used when there are two categorical independent variables (factors) and a continuous dependent variable. It allows for examining the main effects of each factor as well as their interaction effect on the dependent variable. Two-Way ANOVA is suitable when you want to analyze the effects of two independent variables simultaneously. For instance, you might use a Two-Way ANOVA to examine the effects of both gender and age group on the response time of participants in a cognitive task.\n",
    "\n",
    "# 3. Factorial ANOVA: Factorial ANOVA is an extension of the Two-Way ANOVA and is used when there are two or more categorical independent variables (factors) and a continuous dependent variable. It allows for investigating the main effects of each factor as well as their interactions. Factorial ANOVA can be used when you want to analyze the combined effects of multiple independent variables on the dependent variable. For example, in a study on the effects of both diet and exercise on weight loss, a Factorial ANOVA can be used to assess the impact of each factor separately and their interaction.\n",
    "\n",
    "# In summary, One-Way ANOVA is used when there is one independent variable, Two-Way ANOVA is used when there are two independent variables, and Factorial ANOVA is used when there are two or more independent variables. The choice of which ANOVA to use depends on the research question, the number of factors being studied, and the desired level of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2477a6b3-7953-41ab-a583-3a2c0749d8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2448fc6b-1f89-4099-a302-6d3ce3ccaa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The partitioning of variance in ANOVA refers to the decomposition of the total variation in the data into different sources or components of variation. It helps to understand how much of the total variation in the data is due to the differences between groups and how much is due to random variation within the groups. This concept is essential in ANOVA because it allows us to quantify and attribute the sources of variability, providing insights into the significance of the group differences being analyzed.\n",
    "\n",
    "# The partitioning of variance in ANOVA involves three key components:\n",
    "\n",
    "# Between-Groups Variation: This component represents the variability between the group means. It measures the differences among the group means and assesses whether these differences are statistically significant. If the between-groups variation is large relative to the within-group variation, it suggests that the group means are significantly different from each other.\n",
    "\n",
    "# Within-Groups Variation: This component represents the variability within each group. It captures the random variation or noise that is inherent within the groups. It reflects the individual differences or measurement errors within the groups. If the within-groups variation is high, it indicates that there is a substantial amount of random variation, making it difficult to distinguish the true group differences from the noise.\n",
    "\n",
    "# Total Variation: This component represents the overall variability in the data, regardless of group membership. It is the sum of the between-groups and within-groups variation. The total variation reflects the dispersion of scores across all groups. By comparing the between-groups variation to the total variation, ANOVA calculates the proportion of the total variation that can be attributed to the group differences.\n",
    "\n",
    "# Understanding the partitioning of variance helps in assessing the significance of the group differences being studied. By comparing the magnitude of the between-groups variation to the within-groups variation, ANOVA determines whether the observed differences among the group means are larger than what would be expected by chance alone. It provides a statistical basis for evaluating the importance of the independent variable(s) in explaining the variation in the dependent variable(s).\n",
    "\n",
    "# Moreover, the partitioning of variance allows for additional analyses, such as calculating effect sizes, estimating power, and conducting post hoc tests. It provides a structured framework for interpreting the results of ANOVA and understanding the relative contributions of different sources of variation, ultimately aiding in drawing valid conclusions from the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b890a78-7d17-4802-adf6-f348e761bc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ea071a2-8bec-4beb-bbd2-cd8f3268459a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 rows of IRIS dataset : \n",
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n",
      "\n",
      "===================================================================\n",
      "\n",
      "Values for Sepal Length vs Species:\n",
      "SSE: 63.2121\n",
      "SSR: 38.9562\n",
      "SST: 102.1683\n",
      "\n",
      "===================================================================\n",
      "\n",
      "             df     sum_sq    mean_sq           F        PR(>F)\n",
      "species     2.0  63.212133  31.606067  119.264502  1.669669e-31\n",
      "Residual  147.0  38.956200   0.265008         NaN           NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.formula.api import ols\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# Loading Iris dataset from seaborn\n",
    "df_iris = sns.load_dataset('iris')\n",
    "print('Top 5 rows of IRIS dataset : ')\n",
    "print(df_iris.head())\n",
    "print('\\n===================================================================\\n')\n",
    "\n",
    "# Fit the one-way ANOVA model (sepal length vs Species)\n",
    "model = ols('sepal_length ~ species', data=df_iris).fit()\n",
    "\n",
    "# Calculate the sum of squares for the model\n",
    "print('Values for Sepal Length vs Species:')\n",
    "SSE = model.ess\n",
    "SSR = model.ssr\n",
    "SST = SSE + SSR\n",
    "\n",
    "print('SSE:', round(SSE,4))\n",
    "print('SSR:', round(SSR,4))\n",
    "print('SST:', round(SST,4))\n",
    "\n",
    "print('\\n===================================================================\\n')\n",
    "# Print the ANOVA table\n",
    "print(anova_lm(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "755e86c1-039c-4b41-aee6-cf98e6eca7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee967409-72f4-414e-9fc3-d85491101331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effect of Factor1: 0.6520765471325478\n",
      "Main effect of Factor2: 0.18491592889441688\n",
      "Interaction effect: 0.6178948963395011\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(0)\n",
    "n = 50\n",
    "factor1 = np.repeat(['A', 'B'], n)\n",
    "factor2 = np.tile(['X', 'Y'], n)\n",
    "response = np.random.randn(2 * n)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'Factor1': factor1, 'Factor2': factor2, 'Response': response})\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Response ~ Factor1 + Factor2 + Factor1:Factor2', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Extract the main effects and interaction effect from the ANOVA table\n",
    "main_effect_factor1 = anova_table['sum_sq']['Factor1']\n",
    "main_effect_factor2 = anova_table['sum_sq']['Factor2']\n",
    "interaction_effect = anova_table['sum_sq']['Factor1:Factor2']\n",
    "\n",
    "print('Main effect of Factor1:', main_effect_factor1)\n",
    "print('Main effect of Factor2:', main_effect_factor2)\n",
    "print('Interaction effect:', interaction_effect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0999267-6d7c-4929-8fae-ecde2a7ad2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this example, we generate sample data with two factors (Factor1, Factor2) and the corresponding response variable (Response). We then create a DataFrame df to store the data. Next, we fit the two-way ANOVA model using ols from statsmodels.formula.api and calculate the ANOVA table using sm.stats.anova_lm. From the ANOVA table, we extract the main effects (main_effect_factor1, main_effect_factor2) and the interaction effect (interaction_effect). Finally, we print the results.\n",
    "\n",
    "# Note: Make sure you have the statsmodels library installed (pip install statsmodels) before running this code. Also, adjust the data and factor names to match your specific dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9775a683-da3a-49e7-9da9-4db257444ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68a77b35-1596-43cd-b3dd-5c03a9de5f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a one-way ANOVA, the F-statistic is used to test the null hypothesis that the means of all the groups are equal. The p-value associated with the F-statistic helps determine the statistical significance of the observed differences between the groups. In this scenario, an F-statistic of 5.23 and a p-value of 0.02 suggest the following conclusions:\n",
    "\n",
    "# 1. Differences between the groups: The obtained F-statistic of 5.23 indicates that there are differences between the group means. The F-statistic measures the ratio of the between-groups variability to the within-groups variability. A higher F-value implies larger differences between the group means.\n",
    "\n",
    "# 2. Statistical significance: The p-value of 0.02 suggests that the observed differences between the groups are statistically significant at the chosen significance level (typically 0.05 or 0.01). Since the p-value is less than the significance level, we reject the null hypothesis.\n",
    "\n",
    "# Interpretation: Based on these results, we can conclude that there are statistically significant differences between the groups. However, it's important to note that the one-way ANOVA does not provide information about which specific groups differ from each other. To identify the specific group differences, further post hoc tests (e.g., Tukey's HSD, Bonferroni, or pairwise t-tests) can be conducted.\n",
    "\n",
    "# It is also important to consider the effect size and practical significance in addition to statistical significance. The effect size measures the magnitude of the differences between groups and provides a measure of the practical significance or importance of the observed differences. Additionally, interpreting the results should take into account the context and relevant domain knowledge to draw meaningful conclusions about the differences between the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c365f7e-8698-482d-8cf9-394ba9e547e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae7dfa3a-6d3f-4ddb-b0ba-03eb846a8aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing data in a repeated measures ANOVA requires careful consideration to maintain the integrity and validity of the analysis. Here are some common approaches to handling missing data in a repeated measures ANOVA and their potential consequences:\n",
    "\n",
    "# 1. Complete Case Analysis (Listwise deletion): This approach involves excluding any participant with missing data on any variable included in the analysis. The consequence of this method is a reduction in sample size, which can lead to loss of statistical power and potentially biased results if the missingness is related to the variables under study.\n",
    "\n",
    "# 2. Pairwise Deletion (Available Case Analysis): With this approach, participants with missing data are excluded only from analyses involving the variables with missing data, while including them in analyses for variables with complete data. This method retains more data compared to complete case analysis, but it can introduce bias if the missingness is not completely random and is related to the variables being analyzed.\n",
    "\n",
    "# 3. Mean Imputation: In mean imputation, missing values are replaced with the mean value of the variable. This approach assumes that the missing values have the same mean as the observed values. However, mean imputation can underestimate the standard errors and lead to inflated Type I error rates, as it does not account for the uncertainty introduced by imputing the missing values.\n",
    "\n",
    "# 4. Last Observation Carried Forward (LOCF): LOCF involves replacing missing values with the last observed value from the same participant. This method assumes that missing values remain the same as the last observed value, which may not be accurate. LOCF can result in biased estimates and distort the patterns of change over time.\n",
    "\n",
    "# 5. Multiple Imputation: Multiple imputation is a more sophisticated approach that generates multiple plausible imputations for missing values, taking into account the uncertainty of the missing data. This approach creates a set of complete datasets with imputed values, and the analysis is performed on each dataset, combining the results using specific rules. Multiple imputation provides unbiased estimates, preserves variability, and accounts for the uncertainty introduced by imputing missing values.\n",
    "\n",
    "# It is crucial to note that no imputation method can guarantee accurate results, and the choice of handling missing data should depend on the nature of the missingness, the assumptions made, and the specific research context. Sensitivity analyses or exploring multiple approaches can provide insights into the robustness of the findings to different missing data strategies. Consulting with a statistician or data analyst is recommended to determine the most appropriate approach for handling missing data in a repeated measures ANOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "385f0306-0f8d-4559-ac5d-bfa672506311",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "262ae51c-bac6-4c88-903c-490f590be31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After conducting an analysis of variance (ANOVA) and obtaining a significant result, post-hoc tests are often performed to determine which specific group differences are significant. Some common post-hoc tests used after ANOVA include:\n",
    "\n",
    "# 1. Tukey's Honestly Significant Difference (HSD): Tukey's HSD is widely used to compare all possible pairwise group differences. It controls the familywise error rate, making it suitable when you have several groups and want to identify which specific pairs of groups differ significantly.\n",
    "\n",
    "# 2. Bonferroni correction: The Bonferroni correction adjusts the significance level for each comparison to maintain an overall desired alpha level. It is a conservative approach that divides the desired significance level (e.g., 0.05) by the number of pairwise comparisons. Bonferroni correction is commonly used when there are a small number of planned comparisons.\n",
    "\n",
    "# 3. Scheffe's test: Scheffe's test is a conservative post-hoc test that allows for comparisons between any combination of groups. It is more liberal than Tukey's HSD, making it appropriate when dealing with unequal sample sizes or unequal variances.\n",
    "\n",
    "# 4. Dunnett's test: Dunnett's test is used when comparing multiple treatment groups to a control group. It controls the overall error rate, making it suitable for situations where you have a control group and want to determine which treatment groups differ significantly from the control.\n",
    "\n",
    "# Example: Let's consider a scenario where a researcher investigates the effectiveness of three different teaching methods (A, B, and C) on student performance. The researcher conducts a one-way ANOVA and finds a significant overall difference among the groups. To identify which specific pairs of teaching methods differ significantly, a post-hoc test would be necessary.\n",
    "\n",
    "# For instance, the researcher might use Tukey's HSD post-hoc test to compare the mean performance between all possible pairs of teaching methods (A vs. B, A vs. C, and B vs. C). Tukey's HSD will provide adjusted p-values for each pairwise comparison, indicating which specific pairs of teaching methods have significant differences in student performance.\n",
    "\n",
    "# Using a post-hoc test in this situation is essential because the ANOVA only tells us that there are significant differences among the groups, but it does not specify which pairs of groups differ significantly. The post-hoc test allows for a more detailed analysis by identifying the specific group differences, aiding in the interpretation of the results and providing more meaningful insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0003fe47-be43-4b29-a02a-3f792f3c8462",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf1f0878-9505-4581-88ed-f1b6a64e3466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-way ANOVA Results:\n",
      "F-statistic: 18.630408350295305\n",
      "p-value: 6.144679136842842e-08\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(0)\n",
    "diet_A = np.random.normal(loc=5, scale=2, size=50)\n",
    "diet_B = np.random.normal(loc=7, scale=2, size=50)\n",
    "diet_C = np.random.normal(loc=4, scale=2, size=50)\n",
    "\n",
    "# Concatenate the data\n",
    "weight_loss_data = np.concatenate([diet_A, diet_B, diet_C])\n",
    "\n",
    "# Create the group labels\n",
    "groups = np.repeat(['A', 'B', 'C'], 50)\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Report the results\n",
    "print('One-way ANOVA Results:')\n",
    "print('F-statistic:', f_statistic)\n",
    "print('p-value:', p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcd16758-803f-4353-9b31-66a0347356f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this example, we generate sample weight loss data for each diet (A, B, C) using the numpy.random.normal function. We then concatenate the data and create corresponding group labels. Next, we use the stats.f_oneway function from scipy to perform the one-way ANOVA analysis. The function takes the weight loss data for each diet as separate arguments.\n",
    "\n",
    "# Finally, we report the results, including the F-statistic and the p-value.\n",
    "\n",
    "# Interpretation: Based on the results of the one-way ANOVA, if the obtained p-value is less than the chosen significance level (e.g., 0.05), we reject the null hypothesis. If the p-value is greater than the significance level, we fail to reject the null hypothesis. In this case, the F-statistic and p-value obtained from the analysis indicate whether there are significant differences between the mean weight loss of the three diets.\n",
    "\n",
    "# For example, if the reported p-value is less than 0.05, we would conclude that there are significant differences in the mean weight loss between at least two of the three diets (A, B, and C). However, if the p-value is greater than 0.05, we would fail to reject the null hypothesis and conclude that there is no significant difference in the mean weight loss among the three diets.\n",
    "\n",
    "# Note: Adjust the data generation process to match your specific scenario or use your own weight loss dataset in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90692753-8c0f-4381-9170-0cdfd1a30b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc6a312f-3d77-4dd0-854d-795f787891e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated Data example :\n",
      "  Software Experience       Time\n",
      "0        A     Novice  12.828739\n",
      "1        A     Novice  16.994691\n",
      "2        A     Novice  15.565957\n",
      "3        A     Novice  11.987411\n",
      "4        A     Novice  13.842799\n",
      "\n",
      "======================================================================================\n",
      "\n",
      "                             df      sum_sq     mean_sq          F  \\\n",
      "C(Software)                 2.0  204.881181  102.440590  18.135666   \n",
      "C(Experience)               1.0  165.079097  165.079097  29.224933   \n",
      "C(Software):C(Experience)   2.0   17.481552    8.740776   1.547431   \n",
      "Residual                   56.0  316.319953    5.648571        NaN   \n",
      "\n",
      "                                 PR(>F)  \n",
      "C(Software)                8.460472e-07  \n",
      "C(Experience)              1.375177e-06  \n",
      "C(Software):C(Experience)  2.217544e-01  \n",
      "Residual                            NaN  \n",
      "\n",
      "\n",
      "Conclusion: There is a significant main effect of software.\n",
      "Conclusion: There is a significant main effect of experience.\n",
      "Conclusion: There is no significant interaction effect between software and experience.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Setting random seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "# Generating 2 random time samples for novice and expert\n",
    "time_novice = np.random.normal(loc=15, scale=2, size=30)\n",
    "time_expert = np.random.normal(loc=10, scale=2, size=30)\n",
    "\n",
    "# Generate simulated data\n",
    "data = pd.DataFrame({\n",
    "    'Software': ['A']*20 + ['B']*20 + ['C']*20,\n",
    "    'Experience': ['Novice']*30 + ['Experienced']*30,\n",
    "    'Time': list(time_novice)+list(time_expert)\n",
    "})\n",
    "\n",
    "# Print the simulated data head \n",
    "print('Simulated Data example :')\n",
    "print(data.head())\n",
    "\n",
    "print('\\n======================================================================================\\n')\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Time ~ C(Software) + C(Experience) + C(Software):C(Experience)', data=data).fit()\n",
    "table = sm.stats.anova_lm(model, typ=1)\n",
    "\n",
    "# Set significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Main effects and interaction effect\n",
    "print(table)\n",
    "print('\\n')\n",
    "if table['PR(>F)'][0] < alpha:\n",
    "    print(\"Conclusion: There is a significant main effect of software.\")\n",
    "else:\n",
    "    print(\"Conclusion: There is no significant main effect of software.\")\n",
    "\n",
    "if table['PR(>F)'][1] < alpha:\n",
    "    print(\"Conclusion: There is a significant main effect of experience.\")\n",
    "else:\n",
    "    print(\"Conclusion: There is no significant main effect of experience.\")\n",
    "\n",
    "if table['PR(>F)'][2] < alpha:\n",
    "    print(\"Conclusion: There is a significant interaction effect between software and experience.\")\n",
    "else:\n",
    "    print(\"Conclusion: There is no significant interaction effect between software and experience.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f13d07d9-7622-4873-bdd6-5743b33083bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"There is a significant main effect of software\": This means that the software programs used by the employees have a significant impact on the outcome variable (e.g., completion time), independent of the experience level of the employees. This suggests that the choice of software program is an important factor that should be considered carefully when completing this task.\n",
    "\n",
    "# \"There is a significant main effect of experience\": This means that the experience level of the employees has a significant impact on the outcome variable, independent of the software program used. Specifically, this suggests that experienced employees may complete the task faster than novices, or vice versa. This finding can be helpful for the company to identify the best employees for a given task and to provide appropriate training for new employees.\n",
    "\n",
    "# \"There is NO significant interaction effect between software and experience\": This means that the effect of software on the outcome variable does not depend on the experience level of the employees, and vice versa. This suggests that the software programs perform similarly for both novices and experienced employees. This finding can be helpful for the company to decide which software program to use, as they do not need to consider the experience level of the employees when making the choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2519c59c-5032-43d2-9011-00c105bbe13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d7b3699-a493-4c5e-ba43-4f8710cefe96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated data for test_scores:\n",
      "   test_score    group\n",
      "0   70.079124  control\n",
      "1   70.780965  control\n",
      "2   68.814563  control\n",
      "3   69.387097  control\n",
      "4   66.185102  control\n",
      "\n",
      "===============================\n",
      "\n",
      "t-statistic: -28.5074, p-value: 3.096206271894725e-49\n",
      "\n",
      "\n",
      "Reject the Null Hypothesis\n",
      "Conclusion : There is SIGNIFICANT difference in test scores between the control and experimental groups.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Setting numpy random seed\n",
    "np.random.seed(45)\n",
    "\n",
    "# Generating normal test scores with same variance for both control groups\n",
    "test_score_control = np.random.normal(loc=70, scale=3, size=50)\n",
    "test_score_experimental = np.random.normal(loc=85, scale=3, size=50)\n",
    "\n",
    "# Creating the dataframe\n",
    "df = pd.DataFrame({'test_score':list(test_score_control)+list(test_score_experimental),\n",
    "                   'group':['control']*50 + ['experimental']*50})\n",
    "\n",
    "# printing the sample dataframe\n",
    "print('Simulated data for test_scores:')\n",
    "print(df.head())\n",
    "print('\\n===============================\\n')\n",
    "\n",
    "null_hypothesis = \"There is NO difference in test scores between the control and experimental groups.\"\n",
    "alt_hypothesis = \"There is SIGNIFICANT difference in test scores between the control and experimental groups.\"\n",
    "\n",
    "# Conduct the two-sample t-test\n",
    "control_scores = df[df['group'] == 'control']['test_score']\n",
    "experimental_scores = df[df['group'] == 'experimental']['test_score']\n",
    "t_stat, p_val = ttest_ind(control_scores, experimental_scores, equal_var=True)\n",
    "print(f\"t-statistic: {t_stat:.4f}, p-value: {p_val}\")\n",
    "print('\\n')\n",
    "\n",
    "# Significance value \n",
    "alpha = 0.05\n",
    "if p_val<alpha:\n",
    "    print('Reject the Null Hypothesis')\n",
    "    print(f'Conclusion : {alt_hypothesis}')\n",
    "else:\n",
    "    print('Failed to reject the Null Hypothesis')\n",
    "    print(f'Conclusion : {null_hypothesis}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8dc4b3e-5cd2-45d0-9321-836be78e2acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b6ac0b-e09b-4c8f-904d-1b0742f2ddfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
